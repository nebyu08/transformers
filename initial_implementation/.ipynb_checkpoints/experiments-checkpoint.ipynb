{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5fffddf-7e5b-437d-9f22-53df43e3c192",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fcca324-2d04-4684-b3d1-7da5ffc81d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a1664be-f796-4919-bf8f-cf7a55e6cdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dummy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def start(self,sz):\n",
    "        self.temp=torch.randn(size=(sz))\n",
    "        print(f\"original form {self.temp.shape}\")\n",
    "        print(f\"transposed form {self.temp.T.shape[0]} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "598e534f-03bf-4ec3-8913-2413b3005726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original form torch.Size([9, 8])\n",
      "transposed form 8 \n"
     ]
    }
   ],
   "source": [
    "temp=dummy()\n",
    "temp.start((9,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ff5c3aa-a619-4dfd-ad15-46c33fc22b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "def scaled_dot_product(query,key,value,mask_opt=False):\n",
    "    \"\"\"this is going to be used for 3d inputs\"\"\"\n",
    "    k_dim=key.shape[-1]\n",
    "    attention_logits=torch.matmul(query,key.transpose(-2,-1))\n",
    "    attention_logits=attention_logits/math.sqrt(k_dim)\n",
    "    if mask_opt:\n",
    "        attention_logits=attention_logits.masked_fill(mask==0,-float(\"inf\"))\n",
    "    #attention=\n",
    "    attention=F.softmax(attention_logits,dim=1)\n",
    "    values=torch.matmul(attention,value)\n",
    "    return attention,values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b1520e8-3447-4299-912e-7817c468aae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0650, 0.8874, 0.0476],\n",
       "         [0.8402, 0.0479, 0.1119],\n",
       "         [0.6512, 0.3400, 0.0088]]),\n",
       " tensor([[-0.2078, -1.4200, -0.2237,  0.6377],\n",
       "         [-0.8180, -1.4825, -0.1989, -1.1468],\n",
       "         [-0.7608, -1.6635, -0.2225, -0.5771]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len,feat=3,4\n",
    "query=torch.randn(seq_len,feat)\n",
    "key=torch.randn(seq_len,feat)\n",
    "value=torch.randn(seq_len,feat)\n",
    "scaled_dot_product(query,key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4eff6f13-0aad-4f46-8805-08740e1208c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_head(num_heads,embedding_size):\n",
    "    assert embedding_size%num_heads==0\n",
    "    n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d23c99fe-d1d1-4596-9653-fa24c5c83516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9311)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=torch.randn(size=(3,4))\n",
    "p.mean((-2,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b7e31b3-7337-4ff5-b61b-8fdb49170924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original form:tensor([[-1.2221,  0.0481, -1.3141, -0.7992],\n",
      "        [ 0.7929, -0.1115, -1.5939,  0.5758],\n",
      "        [ 1.5076, -0.0941, -0.4303, -1.7666]])\n",
      "tensor([[-0.8792,  0.4272, -0.9738, -0.4442],\n",
      "        [ 1.1932,  0.2631, -1.2616,  0.9700],\n",
      "        [ 1.9283,  0.2810, -0.0648, -1.4393]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,ndim,bias):\n",
    "        super().__init__()\n",
    "        self.ndim=ndim\n",
    "        self.weight=nn.Parameter(torch.ones(ndim))\n",
    "        self.bias=nn.Parameter(torch.zeros(ndim)) if bias else None\n",
    "    def forward(self,x,norm_shape,eps=1e-05,):\n",
    "        return F.layer_norm(x,norm_shape,self.weight,self.bias,eps)\n",
    "\n",
    "norm_shape=(3,4)\n",
    "temp=torch.randn(norm_shape)\n",
    "layer_norm=LayerNorm(ndim=(3,4),bias=True)\n",
    "print(f\"original form:{temp.detach()}\")\n",
    "print(layer_norm(temp,norm_shape).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a9075c8-2262-4334-81a8-0ca4f3d01b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn(size=(3,2))\n",
    "y=x.view(2,3)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f22d2cff-074b-4d6b-9c25-028ecc44b701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9195, -0.8720,  0.0729, -2.2809],\n",
      "        [-0.1928,  1.1296, -0.9557, -0.3651],\n",
      "        [-0.5879, -0.5506,  0.7819,  0.4923]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.randn(size=(3,4))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63198d85-cc54-4cd4-a95c-3a76e017e2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9195, -0.8720,  0.0000,  0.0000],\n",
       "        [-0.1928,  1.1296, -0.9557,  0.0000],\n",
       "        [-0.5879, -0.5506,  0.7819,  0.4923]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(a,diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0a44255-7916-42a5-ba50-aca406fdaa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from base import AttentionHeads,LayerNorm,default_config,Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d444f4f-73d0-44a2-8009-b521ea317f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result after the attention layer is torch.Size([32, 140, 768])\n"
     ]
    }
   ],
   "source": [
    "#experimenting time\n",
    "config=default_config()\n",
    "class_exp=AttentionHeads(default_config)\n",
    "temp=torch.randn(size=(32,140,768))\n",
    "result=class_exp(temp)\n",
    "print(f\"result after the attention layer is {result.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893bc887-ac8b-4431-b237-6122de2af885",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=torch.randn(size=(32,125,768))\n",
    "config=default_config\n",
    "blocks=Block(config)\n",
    "blocks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fe4f1e-90a6-4ca7-bb68-4a7db3e9d0a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
