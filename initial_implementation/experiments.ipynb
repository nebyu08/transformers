{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5fffddf-7e5b-437d-9f22-53df43e3c192",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fcca324-2d04-4684-b3d1-7da5ffc81d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a1664be-f796-4919-bf8f-cf7a55e6cdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dummy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def start(self,sz):\n",
    "        self.temp=torch.randn(size=(sz))\n",
    "        print(f\"original form {self.temp.shape}\")\n",
    "        print(f\"transposed form {self.temp.T.shape[0]} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "598e534f-03bf-4ec3-8913-2413b3005726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original form torch.Size([9, 8])\n",
      "transposed form 8 \n"
     ]
    }
   ],
   "source": [
    "temp=dummy()\n",
    "temp.start((9,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ff5c3aa-a619-4dfd-ad15-46c33fc22b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "def scaled_dot_product(query,key,value,mask_opt=False):\n",
    "    \"\"\"this is going to be used for 3d inputs\"\"\"\n",
    "    k_dim=key.shape[-1]\n",
    "    attention_logits=torch.matmul(query,key.transpose(-2,-1))\n",
    "    attention_logits=attention_logits/math.sqrt(k_dim)\n",
    "    if mask_opt:\n",
    "        attention_logits=attention_logits.masked_fill(mask==0,-float(\"inf\"))\n",
    "    #attention=\n",
    "    attention=F.softmax(attention_logits,dim=1)\n",
    "    values=torch.matmul(attention,value)\n",
    "    return attention,values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b1520e8-3447-4299-912e-7817c468aae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0650, 0.8874, 0.0476],\n",
       "         [0.8402, 0.0479, 0.1119],\n",
       "         [0.6512, 0.3400, 0.0088]]),\n",
       " tensor([[-0.2078, -1.4200, -0.2237,  0.6377],\n",
       "         [-0.8180, -1.4825, -0.1989, -1.1468],\n",
       "         [-0.7608, -1.6635, -0.2225, -0.5771]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len,feat=3,4\n",
    "query=torch.randn(seq_len,feat)\n",
    "key=torch.randn(seq_len,feat)\n",
    "value=torch.randn(seq_len,feat)\n",
    "scaled_dot_product(query,key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4eff6f13-0aad-4f46-8805-08740e1208c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_head(num_heads,embedding_size):\n",
    "    assert embedding_size%num_heads==0\n",
    "    n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d23c99fe-d1d1-4596-9653-fa24c5c83516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9311)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=torch.randn(size=(3,4))\n",
    "p.mean((-2,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b7e31b3-7337-4ff5-b61b-8fdb49170924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original form:tensor([[-1.2221,  0.0481, -1.3141, -0.7992],\n",
      "        [ 0.7929, -0.1115, -1.5939,  0.5758],\n",
      "        [ 1.5076, -0.0941, -0.4303, -1.7666]])\n",
      "tensor([[-0.8792,  0.4272, -0.9738, -0.4442],\n",
      "        [ 1.1932,  0.2631, -1.2616,  0.9700],\n",
      "        [ 1.9283,  0.2810, -0.0648, -1.4393]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,ndim,bias):\n",
    "        super().__init__()\n",
    "        self.ndim=ndim\n",
    "        self.weight=nn.Parameter(torch.ones(ndim))\n",
    "        self.bias=nn.Parameter(torch.zeros(ndim)) if bias else None\n",
    "    def forward(self,x,norm_shape,eps=1e-05,):\n",
    "        return F.layer_norm(x,norm_shape,self.weight,self.bias,eps)\n",
    "\n",
    "norm_shape=(3,4)\n",
    "temp=torch.randn(norm_shape)\n",
    "layer_norm=LayerNorm(ndim=(3,4),bias=True)\n",
    "print(f\"original form:{temp.detach()}\")\n",
    "print(layer_norm(temp,norm_shape).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a9075c8-2262-4334-81a8-0ca4f3d01b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn(size=(3,2))\n",
    "y=x.view(2,3)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f22d2cff-074b-4d6b-9c25-028ecc44b701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9195, -0.8720,  0.0729, -2.2809],\n",
      "        [-0.1928,  1.1296, -0.9557, -0.3651],\n",
      "        [-0.5879, -0.5506,  0.7819,  0.4923]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.randn(size=(3,4))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63198d85-cc54-4cd4-a95c-3a76e017e2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9195, -0.8720,  0.0000,  0.0000],\n",
       "        [-0.1928,  1.1296, -0.9557,  0.0000],\n",
       "        [-0.5879, -0.5506,  0.7819,  0.4923]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(a,diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0a44255-7916-42a5-ba50-aca406fdaa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from base import AttentionHeads,LayerNorm,default_config,Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1d444f4f-73d0-44a2-8009-b521ea317f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result after the attention layer is torch.Size([32, 140, 768])\n"
     ]
    }
   ],
   "source": [
    "#experimenting time\n",
    "config=default_config()\n",
    "class_exp=AttentionHeads(default_config)\n",
    "temp=torch.randn(size=(32,140,768))\n",
    "result=class_exp(temp)\n",
    "print(f\"result after the attention layer is {result.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6a54a77a-e8af-4d17-b5c0-0c913ca930b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(531441)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.pow(torch.tensor(3),12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "53fe4f1e-90a6-4ca7-bb68-4a7db3e9d0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape is torch.Size([32, 150, 768])\n"
     ]
    }
   ],
   "source": [
    "config=default_config\n",
    "blocks=Block(config)\n",
    "result=blocks(torch.randn(32,150,768))\n",
    "print(f\"shape is {result.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dcbbe428-720b-4e73-b4b3-1d41e2080993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.0781)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84c73aa9-8d39-4a9e-bdc6-bf9ff07567f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CfgNonde' object has no attribute 'emb_drop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m config\u001b[38;5;241m.\u001b[39mnum_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[0;32m     11\u001b[0m config\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m gpt\u001b[38;5;241m=\u001b[39m\u001b[43mGPT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m config\u001b[38;5;241m=\u001b[39mCN()\n\u001b[0;32m     16\u001b[0m config\u001b[38;5;241m.\u001b[39mn_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\n",
      "File \u001b[1;32m~\\Documents\\deep_learning_scratch\\Transformer_implementation\\initial_implementation\\base.py:127\u001b[0m, in \u001b[0;36mGPT.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    120\u001b[0m type_given\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m type_given\u001b[38;5;241m^\u001b[39mparams_given,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meither specify the modl type or give the hyper-parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m#this makes either the model is given or the parameters of the model is given\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformes\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mModuleDict(\u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    125\u001b[0m     wte\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mEmbedding(config\u001b[38;5;241m.\u001b[39mvocab_size,config\u001b[38;5;241m.\u001b[39memb_size),  \u001b[38;5;66;03m#this is the word to embdding dimension\u001b[39;00m\n\u001b[0;32m    126\u001b[0m     etp\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mEmbedding(config\u001b[38;5;241m.\u001b[39mblock_size,config\u001b[38;5;241m.\u001b[39memb_size),  \u001b[38;5;66;03m#this is adding of the positional embedding to each tokens(embdding know)\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     drop\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mDropout(\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memb_drop\u001b[49m),\n\u001b[0;32m    128\u001b[0m     blocks\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mModuleList([Block(config) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mn_layers)]),\n\u001b[0;32m    129\u001b[0m     ly_n\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mDropout(config\u001b[38;5;241m.\u001b[39memb_size)\n\u001b[0;32m    130\u001b[0m ))\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m#this is the last layer(the language model head)\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(config\u001b[38;5;241m.\u001b[39memb_size,config\u001b[38;5;241m.\u001b[39mvocab_size)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CfgNonde' object has no attribute 'emb_drop'"
     ]
    }
   ],
   "source": [
    "from base import GPT\n",
    "from utils import CfgNonde as CN\n",
    "\n",
    "config=CN()\n",
    "\n",
    "config.n_layers=3\n",
    "config.emb_size=300\n",
    "config.block_size=120\n",
    "config.vocab_size=300\n",
    "config.num_heads=3\n",
    "config.model_type=None\n",
    "\n",
    "gpt=GPT(config)\n",
    "\n",
    "config=CN()\n",
    "config.n_layers=3\n",
    "config.emb_size=300\n",
    "config.block_size=120\n",
    "config.vocab_size=300\n",
    "config.num_heads=3\n",
    "config.model_type=None\n",
    "\n",
    "gpt=GPT(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9483e9cb-239a-4820-b831-1b4ffe5e2632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
